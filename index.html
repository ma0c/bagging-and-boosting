<!DOCTYPE html>
<html>
<head>
    <title>Una guía rápida de Docker</title>
    <meta charset="utf-8">
    <style>
        @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
        @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
        @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

        body { font-family: 'Droid Serif'; }
        h1, h2, h3 {
            font-family: 'Yanone Kaffeesatz';
            font-weight: normal;
        }
        .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }

        blockquote.twitter-tweet {
          display: inline-block;
          font-family: "Helvetica Neue", Roboto, "Segoe UI", Calibri, sans-serif;
          font-size: 12px;
          font-weight: bold;
          line-height: 16px;
          border-color: #eee #ddd #bbb;
          border-radius: 5px;
          border-style: solid;
          border-width: 1px;
          box-shadow: 0 1px 3px rgba(0, 0, 0, 0.15);
          margin: 10px 5px;
          padding: 0 16px 16px 16px;
          max-width: 468px;
        }

        blockquote.twitter-tweet p {
          font-size: 16px;
          font-weight: normal;
          line-height: 20px;
        }

        blockquote.twitter-tweet a {
          color: inherit;
          font-weight: normal;
          text-decoration: none;
          outline: 0 none;
        }

        blockquote.twitter-tweet a:hover,
        blockquote.twitter-tweet a:focus {
          text-decoration: underline;
        }
    </style>
    <link rel="stylesheet" type="text/css" href="vendor/remark/remark_theme.css"/>
</head>
<body>
<textarea id="source">

class: center, middle, light

# Ensamble y Meta algoritmos
## Bagging y Boosting

### Mauricio Collazos

<!--.footnote.left[]-->
---
class: center
[Repositorio en github](https://github.com/ma0c/bagging-and-boosting)
![https://github.com/ma0c/bagging-and-boosting](img/qr.png)

---

class: center
# Evaluación de modelos
![Evaluación de un modelo](img/modelo-venn.png)

---
class: center
# Evaluación de modelos
Medida|Formula
-|-
Exactitud| $$\frac{VP+VN}{P+N}$$
Tasa de error| $$\frac{FP+FN}{P+N}$$
Sensibilidad| $$\frac{VP}{P}$$
Especificidad| $$\frac{VN}{N}$$
Precisión| $$\frac{VP}{VP+VN}$$

---
# Cómo se prueban los modelos?

- Muestreo aleatorio
- Validación cruzada
- Bootstrap
---
# Muestreo aleatorio

![holdout](img/holdout.png)

Se divide el conjunto total de datos en un segmento para entretamiento y otro para pruebas, combinaciones comunes son
dividir en tomar $$2/3$$ para entrenamiento y $$1/3$$ para pruebas o tomar 70% de los datos para
entrenamiento y 30% para pruebas


---
# Validación cruzada
![cross_validation](img/cross_validation.png)

Se divide el conjunto total de datos en `k` particiones *sin reemplazo*, para entretar `k` modelos distintos

---
# Bootstrapping
![bootstrapping](img/bootstrapping.png)

Se divide el conjunto total de datos en `k` particiones *con reemplazo*, para entretar `k` modelos distintos

---
# Bootstrap aggregating (Bagging)

Propuesto en 1994 por Leo Breiman proponiendo dados subconjuntos de la misma distribución,crear una secuencia de
clasificadores y predictores y generar un concenso para la solución -
[Ver artículo](https://www.stat.berkeley.edu/~breiman/bagging.pdf)

```python
def entrenar_modelos(datos_de_entrenamiento: list, numero_de_bolsas: int):
    modelos = list()
    bolsas = dividir_con_reemplazo(datos_de_entrenamiento, numero_de_bolsas)
    for bolsa in bolsas:
        nuevo_modelo = entrenar_modelo(bolsa)
        modelos.append(nuevo_modelo)
    return modelos
```

```python
def evaluar_modelos(datos_de_prueba: list, modelos_entrenados: list):
    evaluaciones_parciales = list()
    for modelo in modelos_entrenados:
        evaluacion = modelo.evaluar(datos_de_prueba)
        evaluaciones_parciales.append(evaluacion)
    return promedio(evaluaciones_parciales)
```

---
# Bootstrap aggregating (Bagging)

Algunas implementaciones sobre estructuras de árboles

- Bagged Decision Trees
- Random Forest
- Extra Trees
---

# Bootstrap aggregating (Bagging) en Python
```python
from sklearn.ensemble import BaggingClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier

iris = datasets.load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
decision_tree = DecisionTreeClassifier()
bagging_classifier = BaggingClassifier(base_estimator=decision_tree, n_estimators=100)

model = bagging_classifier.fit(X_train, y_train)
y_pred=model.predict(X_test)
metrics.accuracy_score(y_test, y_pred)
```
---
# Boosting

Propuesto en 1995 por Freund y Schapire basado en la actualización de pesos LittlestoneWarmuth de subconjuntos de datos
sobre aprendedores débiles para maximizar la precisión - [Ver artículo](https://www.sciencedirect.com/science/article/pii/S002200009791504X?via%3Dihub)

```python
def entrenar_modelo(datos_de_entrenamiento: list, numero_de_modelos: int):
    pesos_de_datos = generar_pesos_uniformes(datos_de_entrenamiento)
    modelos = list()
    exactitudes = list()
    for i in range(numero_de_modelos):
        bolsa = dividir_con_reemplazo_y_peso(datos_de_entrenamiento, numero_de_modelos, pesos_de_datos)
        nuevo_modelo = entrenar_modelo(bolsa)
        pesos_de_datos = actualizar_pesos(nuevo_modelo, bolsa)
        exactitud_modelo = calcular_presicion(nuevo_modelo, bolsa)
        modelos.append(nuevo_modelo)
        exactitudes.append(nuevo_modelo)
    modelo = generar_modelo_con_pesos(modelos, exactitudes)
    return modelo
```

---
# Boosting

Algunas implementaciones populares del algoritmo

- AdaBoost
- Stochastic Gradient Boosting

---
# AdaBoosting

Propuesto en 1999 por Freund y SchapirePresenta una solución práctica a los problemas teóricos del boosting
[Ver Artículo](https://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf)

Dado
    $$ (x_1, y_1), ... , (x_m,y_m)\ donde\ x_i \in X \ ,\ \  y_i \in Y = \\{ -1, 1 \\} $$

Inicializar $$ D_1(i) = 1/m $$

Desde t = 1 hasta t = T

Entrene un modelo usando $$ D_t $$

Obtenga las hipotesis débiles $$ h_t: X \to \\{ -1,1 \\} $$

---

con el error

$$ \epsilon_{t} = Pr_i \sim D_t [h_t(x_i) \neq y_i] $$

Escoja un

$$ \alpha_t = \frac{1}{2}ln(\frac{1-\epsilon_t}{\epsilon_t}) $$

Actualice:

$$ D_{t+1}(i)=\frac{D_t(i)}{Z_t}\times \\{ \begin{array}{lcc} e^{-\alpha_t} & if & h_t(x_i) = y_i \lor e^{\alpha_t} & if & h_t(x_i) \neq y_i \\  \end{array}    \\}$$

$$ D_{t+1}(i)=\frac{D_t(i) e^{-\alpha_t y_i h_t(x_i)}} {Z_t} $$

Donde  Z_t es un factor de normalización

Fin desde

La hipotesis final

$$ H(x) = sign(\sum_{t=1}^T \alpha_t h_t(x_i)) $$

---
# AdaBoosting en Python

```python
from sklearn.ensemble import AdaBoostClassifier
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier

iris = datasets.load_iris()
X = iris.data
y = iris.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)
decision_tree = DecisionTreeClassifier()
bagging_classifier = AdaBoostClassifier(base_estimator=decision_tree, n_estimators=100)

model = bagging_classifier.fit(X_train, y_train)
y_pred=model.predict(X_test)
metrics.accuracy_score(y_test, y_pred)
```

</textarea>
<script src="vendor/remark/remark.min.js"></script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<script>
    var slideshow = remark.create();
    // Setup MathJax
      MathJax.Hub.Config({
          tex2jax: {
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
          }
      });

      MathJax.Hub.Configured();
</script>
</body>
</html>